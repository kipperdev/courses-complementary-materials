# O que √© o NGINX?

O NGINX √© um servidor web, que lida com requisi√ß√µes HTTP

Receber requisi√ß√µes (em um porta) e:

- Redireciona essas requisi√ß√µes para as aplica√ß√µes mapeadas (transfere a responsabilidade)
- retorna o recurso est√°tico solicitado
- √â como um gateway/port√£o de entrada para nossa arquitetura
    - Outro servidor muito famoso que faz isso √© o Apache
- A grande sacada do NGINX √© que ele n√£o trabalha com um processo para cada requisi√ß√£o como o Apache faz
- O NGIX trabalha com um processo m√£e com alguns workers (normalmente de acordo com a quantidade de n√∫cleos da CPU no qual ele est√° rodando)
- Os workers executam de forma ass√≠ncrona e concorrente, o que traz uma performance muito interessante

## Detalhes sobre o Nginx

Al√©m disso, o NGINX tamb√©m tem suporte a cache de requisi√ß√µes. Dessa forma a gente consegue reaproveitar dados j√° retornados uma vez (como por exemplo recursos est√°ticos) e retornar a mesma resposta sempre que receber a mesma requisi√ß√£o.

Outro ponto positivo de utilizar o NGINX √© que expomos para a internet apenas um ponto de entrada para nossa estrutura (todos nossos servidores/aplica√ß√µes) ficaram "escondidos" atr√°s do NGINX (que ir√° receber as requisi√ß√µes e ent√£o encaminhar para a aplica√ß√£o respons√°vel) e dessa maneira mantemos nossas aplica√ß√µes privadas dentro da nossa rede e menos pontos de contato que diminui chances de ataques.

Um caso onde o NGNIX √© muito utilizado √© para agregar em um √∫nico ponto exposto todos nossos microservi√ßos (conceito de API Gateway)

- Ent√£o os clientes do nosso app sempre v√£o chamar fernandakipper.com/user /pay /checkout, mas no fundo dos panos isso estar√° sendo redirecionado para cada microservi√ßo respons√°vel por aquele endpoint

Al√©m disso, conseguimos usar o NGINX para trabalhar com comunica√ß√£o encriptografada. Ent√£o o frontend envia para o  servidor NGINX criptografada, e o √∫nico que consegue descriptograr √© o NGINX.

## Proxy x Proxy Reverso

Sempre quando falamos sobre NGINX o termo surge √© PROXY REVERSO

Isso significa que o NGINX responde em nome das nossas aplica√ß√µes.

Mas para entender como isso funciona, primeiro precisamos entender o termo PROXY

### Proxy

Quando falamos sobre o termo PROXY, significa que ele atua como um middleman, que conecta o nosso computador ou servidor com a internet
Ele filtra e bloqueia essas requisi√ß√µes que saem e chegam antes delas realmente chegarem do outro lado, atuando como um escudo entre a rede privada e rede p√∫blica

√â isso que as empresas utilizam para bloquear que a gente acesse alguns sites ou fa√ßa download de algumas coisas na internet, fazendo com que todo tr√°fego de internet seja roteado por um proxy.

Ele pode tamb√©m logar as requisi√ß√µes que est√£o sendo feitas por cada usu√°rio na rede, pra mostrar quais sites esses usu√°rios est√£o acessando
Outra coisa que um proxy pode fazer √© gerenciar caches, para evitar que requisi√ß√µes iguais gerem traf√©go desnecess√°rio, cacheando a resposta por um tempo e retornando ela sem nem mesmo bater no servidor final

### Proxy Reverso

Agora um proxy reverso √© o PROXY do lado do servidor
Ou seja, protegendo uma rede de aplica√ß√µes (um conjunto de servidores que formam uma aplica√ß√£o, como por exemplo todos os servidores backend do Mercado Livre)

Ele vai ter todas as features de um PROXY, mas agora protegendo os servidores backend, fazendo com que todos eles estejam protegidos na rede privada da infraestrutura aonde foram hospedados e a porta de acesso para a internet seja somente atrav√©s do PROXY REVERSO. Ou seja, todas requisi√ß√µes que forem enviadas para esses servidores, passaram pelo proxy reverso primeiro, que ir√° expor um entrypoint e ent√£o filtrar e redirecionar o trafego para o servidor respons√°vel

# Como configurar

## Instalando

Existem v√°rias op√ß√µes para gente instalar e configurar o Nginx

1. Via docker
2. Diretamente no PC

Vamos seguir diretamente pelo PC para que n√£o seja necess√°rio voc√™ saber Docker nesse momento

**MAC:**

```bash
// instala
brew install nginx
sudo apt install nginx

// executa
brew services start nginx
```

**WINDOWS:**

1. [Instala o execut√°vel](https://nginx.org/en/download.html)
2. Extraia o zip para sua pasta de prefer√™ncia (vou usar como exemplo a pasta downloads)
3. Executa o arquivo

```bash
cd C:/downloads/nginx
nginx
```

Agora ao abrir http://localhost:8080/ na porta 8080 no seu navegador, voc√™ deveria ver uma p√°gina como essa:

![Screenshot 2025-08-02 at 11.16.47.png](https://github.com/kipperdev/courses-complementary-materials/blob/main/extra/nginx/Screenshot_2025-08-02_at_11.16.47.png)

## Arquivo de configura√ß√£o

Todo servidor de nginx √© configurado atrav√©s de um arquivo de configura√ß√£o comumente chamado de `nginx.conf`

Quando usamos o comando `nginx -h` para verificar os detalhes do Nginx que acabamos de instalar na nossa m√°quina, vamos observar o local onde ele foi instalado e onde est√° o arquivo de configura√ß√£o default que nosso servidorzinho  est√° usando

![Screenshot 2025-08-02 at 11.17.34.png](https://github.com/kipperdev/courses-complementary-materials/blob/main/extra/nginx/Screenshot_2025-08-02_at_11.17.34.png)

Se abrirmos esse arquivo de configura√ß√£o em um editor de c√≥digo, por exemplo com o vscode

```bash
code /opt/homebrew/etc/nginx/nginx.conf
```

Veremos que ele se parece com o seguinte:

```bash

worker_processes  1;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;

    keepalive_timeout  65;

    server {
        listen       8080;
        server_name  localhost;

        location / {
            root   html;
            index  index.html index.htm;
        }

        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }

    include servers/*;
}

```

<aside>
üö®

**ATEN√á√ÉO:** Eu omiti as linhas comentadas que vem por padr√£o, para facilitar nossa visualiza√ß√£o das configura√ß√µes que est√£o sendo aplicadas. 
Os coment√°rios que vem por padr√£o no arquivo nginx.conf servem para te guiar para fazer configura√ß√µes extras ou novas.
Exemplo:

```

#user  nobody;
worker_processes  1;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;
```

</aside>

## Entendendo as configura√ß√µes

- `worker_processes`
    - Define o n√∫mero de processos de trabalho (workers) que o Nginx vai iniciar. Geralmente √© definido igual ao n√∫mero de n√∫cleos de CPU dispon√≠veis, mas aqui est√° fixado em 1.
- `worker_connections`
    - Define configura√ß√µes relacionadas aos eventos. O `worker_connections` determina o n√∫mero m√°ximo de conex√µes simult√¢neas que cada processo worker pode aceitar.
- `http` {
    - In√≠cio do bloco de configura√ß√£o do m√≥dulo HTTP, que gerencia requisi√ß√µes web.
- `include       mime.types;`
    - Inclui o arquivo `mime.types`, que associa extens√µes de arquivos a tipos MIME, permitindo que o Nginx envie o `Content-Type` correto nas respostas.
- `default_type  application/octet-stream;`
    - Define o tipo MIME padr√£o para arquivos cuja extens√£o n√£o foi reconhecida. `application/octet-stream` √© usado para dados bin√°rios gen√©ricos.
- `sendfile        on;`
    - Ativa o uso do `sendfile()`, uma chamada de sistema eficiente para envio de arquivos, melhorando a performance.
- `keepalive_timeout  65;`
    - Define o tempo (em segundos) que a conex√£o ficar√° aberta aguardando novas requisi√ß√µes antes de ser encerrada.
- `server {`
    - In√≠cio do bloco que define um servidor virtual (host).
- `listen       8080;`
    - O servidor ir√° escutar a porta 8080 por conex√µes HTTP.
- `server_name  localhost;`
    - Define o nome do servidor (hostname) para correspond√™ncia com o `Host` da requisi√ß√£o. Neste caso, aceita apenas `localhost`.
- `location /`
    - Define o comportamento para as requisi√ß√µes que chegarem na raiz do server_name (`/`).
    - `root   html;`
        - Os arquivos ser√£o servidos a partir da pasta `html`
    - `index  index.html index.htm;`
        - e, caso n√£o seja especificado um arquivo, tentar√° carregar `index.html` ou `index.htm`.
- error_page   500 502 503 504  /50x.html;
    - Define uma p√°gina de erro customizada para os c√≥digos de erro 500, 502, 503 e 504. Redireciona para o caminho `/50x.html`.
- location = /50x.html {
    - Especifica onde est√° localizado o arquivo `/50x.html` no sistema de arquivos, que ser√° servido a partir da pasta `html`
- include servers/*;
    - Inclui todos os arquivos de configura√ß√£o dentro do diret√≥rio `servers/`. √ötil para organizar m√∫ltiplos blocos `server` separados.

## Nosso primeiro servidor personalizado

Se observamos na √∫ltima linha do nosso arquivo de configura√ß√£o, ele indica que est√° sendo inclu√≠do uma pasta `servers`

```bash
    include servers/*;
```

Dentro dessa pasta existe outro arquivo de configura√ß√£o que inclu√≠ servidores personalizados, para isso podemos navegar at√© a pasta raiz onde est√° nosso arquivo `nginx.conf`

```bash
 cd /opt/homebrew/etc/nginx/
```

<aside>
üö®

Voc√™ vai obter essa pasta raiz executando o comando `nginx -h` e vendo onde ele foi instalado no seu computador

![Screenshot 2025-08-02 at 11.25.52.png](https://github.com/kipperdev/courses-complementary-materials/blob/main/extra/nginx/Screenshot_2025-08-02_at_11.25.52.png)

</aside>

E dentro dessa pasta vamos navegar/criar a pasta server, e ent√£o criar um arquivo chamado `default.conf`

```bash
 cd /opt/homebrew/etc/nginx/
 mkdir servers
 code .
```

![Screenshot 2025-08-02 at 11.26.54.png](https://github.com/kipperdev/courses-complementary-materials/blob/main/extra/nginx/Screenshot_2025-08-02_at_11.26.54.png)

Dentro desse arquivo de configura√ß√£o vamos apontar para uma pasta nova que contenha a nossa p√°gina personalizada

```bash
server {
    listen       3000;
    server_name  localhost;

    location / {
        root   /Users/fernandakipper/Desktop/server;
        index  index.html index.htm;
    }

}
```

Voc√™ pode fazer o download desse arquivo HTML e colocar na sua pasta de prefer√™ncia, mas tome bastante cuidado para a sua configura√ß√£o do nginx apontar para localiza√ß√£o exata da pasta onde voc√™ colocou o arquivo `index.html`

[index.html](https://github.com/kipperdev/courses-complementary-materials/blob/main/extra/nginx/index.html)

[50x.html](https://github.com/kipperdev/courses-complementary-materials/blob/main/extra/nginx/50x.html)

No meu caso, eu criei uma pasta server na minha √°rea de trabalho (Desktop) e coloquei o arquivo l√°   `/Users/fernandakipper/Desktop/server;`

Agora para reiniciarmos nosso servidor do nginx, para que ele leia essa nova configura√ß√£o que adicionamos, devemos executar no terminal

```bash
nginx -s reload
```

E acessar a porta `3000`  que foi onde colocamos esse nosso arquivo novo de configura√ß√£o para ouvir

![Screenshot 2025-08-02 at 11.39.22.png](https://github.com/kipperdev/courses-complementary-materials/blob/main/extra/nginx/Screenshot_2025-08-02_at_11.39.22.png)

## Configurando um Proxy Reverso

O papel mais comum para servidores Nginx √© servir como um proxy reverso, por isso vamos entender como fazer essa configura√ß√£o.
Ao inv√©s de ter 2 servers nginx rodando, vamos fazer o nosso nginx apontar a requisi√ß√£o, ou seja redirecionar ela, para um servidor que j√° est√° rodando na nossa m√°quina (podendo ser o servidorzinho que criamos antes ou uma nova aplica√ß√£o).
Para fazer isso √© bem simples, quando a requisi√ß√£o chegar na location que queremos ouvir, ao inv√©s de apontar ela para uma pasta com os arquivos da aplica√ß√£o, vamos direcionar ela para onde o nosso servidor da aplica√ß√£o est√° rodando e ouvindo.

Fazemos isso atrav√©s da config `proxy_pass`

```bash
http {
    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;

    keepalive_timeout  65;

    server {
        listen       8080;
        server_name  localhost;

        location / {
            proxy_pass http://localhost:3001;
        }

        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }

    include servers/*;
}

```

# API Gateway

## O que √©?

Podemos usar o Nginx como um API Gateway, onde ele vai atuar como um √∫nico ponto de entrada para todos nossos servi√ßos/servidores, e ent√£o a partir do ponto de entrada ele redireciona para o servidor correspondente que deve lidar com essa requisi√ß√£o.
**Para o cliente, ele est√° sempre acessando a mesma URL, s√≥ mudando o endpoint
Mas para o servidor nginx, ele est√° por baixo dos panos roteando para aplica√ß√µes diferentes**

```bash
http {
    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;

    keepalive_timeout  65;

    server {
        listen       8080;
        server_name  localhost;

        location / {
            proxy_pass http://localhost;
        }
        
	      location /api {
            proxy_pass http://localhost:8000/;
        }
        
	      location /auth {
            proxy_pass http://localhost:3200/;
        }

        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }

    include servers/*;
}
```

<aside>
üö®

ATEN√á√ÉO: Note que √© importante manter na configura√ß√£o do proxy_pass a barra `/` no final da url Pois dessa maneira o nginx n√£o ir√° incluir o prefixo `/api` ou `/auth` quando for repassar a requisi√ß√£o para cada servidor correspondente. Ele vai apenas agregar o resto da rota

</aside>

### Exemplo:

Configura√ß√£o (com barra):

```bash
  location /api {
      proxy_pass http://localhost:8000/;
  }
```

Acesso:

```bash
http://localhost:8080/api/user ---> redirecionado para
  ---->  http://localhost:8000/user 
```

Configura√ß√£o (sem barra):

```bash
  location /api {
      proxy_pass http://localhost:8000;
  }
```

Acesso:

```bash
http://localhost:8080/api/user ---> redirecionado para
  ---->  http://localhost:8000/api/user 
```

### Desvantagem

Ao usar API Gateways, n√≥s temos um √∫nico ponto de falha para nossa arquitetura distr√≠buida
Pois ele acaba sendo o centralizador e redirecionador de todas requisi√ß√µes, e caso ele caia, toda minha aplica√ß√£o cai (mesmo que esteja quebrada em microservi√ßos), pois as requisi√ß√µes n√£o ser√£o enviadas ao microservi√ßo respons√°vel (mesmo que ele continue de p√©)

Mas existem j√° diversas t√©cnicas para monitorar e previnir esse problema. 
O pr√≥prio NGINX √© um servi√ßo super perform√°tico e todo pensado para lidar com essa desvantagem e oferecer o minino de risco poss√≠vel

# Load Balancing

## O que √©?

O NGINX tamb√©m pode ser usado como um Load Balancer, distribuindo as requisi√ß√µes entre as diferentes inst√¢ncias do nosso app cadastradas no nosso NGINX.

- ele faz essa distribui√ß√£o de requisi√ß√µes para evitar com que uma inst√¢ncia fique muito sobrecarregada enquanto outra est√° parada (esse √© o conceito geral de load balancing)
- esse balanceamento de carga √© feito com algoritmos de balancemaento como o round robbin e outras estrat√©gias

## Como configurar

Vamos precisar um bloco de server que ouve uma location e ent√£o distribui as requisi√ß√µes dentre as inst√¢ncias dispon√≠veis

```bash
upstream available_servers {
	server localhost:8001;
	server localhost:8002;
}

server {
    listen       3001;
    server_name  localhost;

    location / {
        proxy_pass http://available_servers;
    }
}
```

Perceba que n√≥s declaramos um novo bloco, chamado de `upstream`  (que nada mais √© que um grupo de servidores) e chamamos de `available_servers`

Agora quando esse nome `available_servers` for referenciado como um destino final, o nginx por padr√£o j√° sabe que deve aplicar um algoritmo de balanceamento de carga e enviar hora para o que est√° na porta 8001 ou 8002

Nesse caso simples, ele faz 50/50